{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otto Grop product classification project from [kaggle competition](https://www.kaggle.com/c/otto-group-product-classification-challenge/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61878, 94) (144368, 93)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv', index_col = 'id')\n",
    "X_test = pd.read_csv('data/test.csv', index_col = 'id')\n",
    "\n",
    "print(train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "id                                                                           \n",
       "1        1       0       0       0       0       0       0       0       0   \n",
       "2        0       0       0       0       0       0       0       1       0   \n",
       "3        0       0       0       0       0       0       0       1       0   \n",
       "4        1       0       0       1       6       1       5       0       0   \n",
       "5        0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "    feat_10   ...     feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "id            ...                                                            \n",
       "1         0   ...           1        0        0        0        0        0   \n",
       "2         0   ...           0        0        0        0        0        0   \n",
       "3         0   ...           0        0        0        0        0        0   \n",
       "4         1   ...           0        1        2        0        0        0   \n",
       "5         0   ...           1        0        0        0        0        1   \n",
       "\n",
       "    feat_91  feat_92  feat_93   target  \n",
       "id                                      \n",
       "1         0        0        0  Class_1  \n",
       "2         0        0        0  Class_1  \n",
       "3         0        0        0  Class_1  \n",
       "4         0        0        0  Class_1  \n",
       "5         0        0        0  Class_1  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, :-1]\n",
    "y = train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "model = LGBMClassifier(random_state=random_state)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.801147382029735"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "(y_val == y_pred).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 best iteration = 1000, Score = 1.959302\n",
      " 1 best iteration = 1000, Score = 0.477120\n",
      " 2 best iteration = 1000, Score = 1.447886\n",
      " 3 best iteration = 1000, Score = 0.563794\n",
      " 4 best iteration = 1000, Score = 0.476520\n",
      " 5 best iteration = 1000, Score = 1.958634\n",
      " 6 best iteration = 1000, Score = 1.959206\n",
      " 7 best iteration = 1000, Score = 1.959175\n",
      " 8 best iteration = 1000, Score = 1.959362\n",
      " 9 best iteration = 1000, Score = 1.955063\n",
      "10 best iteration = 1000, Score = 1.959364\n",
      "11 best iteration = 1000, Score = 1.959269\n",
      "12 best iteration = 1000, Score = 1.954499\n",
      "13 best iteration = 1000, Score = 1.957079\n",
      "14 best iteration = 1000, Score = 1.163607\n",
      "15 best iteration = 1000, Score = 1.959349\n",
      "16 best iteration = 1000, Score = 1.940409\n",
      "17 best iteration = 1000, Score = 1.959367\n",
      "18 best iteration = 1000, Score = 1.959016\n",
      "19 best iteration = 1000, Score = 1.959366\n",
      "20 best iteration = 999, Score = 0.466578\n",
      "21 best iteration = 1000, Score = 1.939771\n",
      "22 best iteration = 1000, Score = 1.959296\n",
      "23 best iteration = 1000, Score = 0.482146\n",
      "24 best iteration = 1000, Score = 1.851909\n",
      "25 best iteration = 1000, Score = 1.936615\n",
      "26 best iteration = 290, Score = 0.477120\n",
      "27 best iteration = 1000, Score = 0.953602\n",
      "28 best iteration = 1000, Score = 0.569150\n",
      "29 best iteration = 1000, Score = 1.886917\n",
      "30 best iteration = 1000, Score = 1.959078\n",
      "31 best iteration = 1000, Score = 1.959367\n",
      "32 best iteration = 1000, Score = 1.959338\n",
      "33 best iteration = 1000, Score = 1.673180\n",
      "34 best iteration = 1000, Score = 1.955685\n",
      "35 best iteration = 1000, Score = 1.871191\n",
      "36 best iteration = 1000, Score = 1.958594\n",
      "37 best iteration = 1000, Score = 0.767007\n",
      "38 best iteration = 1000, Score = 1.954105\n",
      "39 best iteration = 1000, Score = 1.959363\n",
      "40 best iteration = 1000, Score = 1.958860\n",
      "41 best iteration = 1000, Score = 1.957973\n",
      "42 best iteration = 1000, Score = 1.958859\n",
      "43 best iteration = 1000, Score = 1.682844\n",
      "44 best iteration = 1000, Score = 0.492201\n",
      "45 best iteration = 1000, Score = 1.794663\n",
      "46 best iteration = 1000, Score = 1.959366\n",
      "47 best iteration = 1000, Score = 1.959323\n",
      "48 best iteration = 1000, Score = 1.902274\n",
      "49 best iteration = 1000, Score = 1.959361\n",
      "50 best iteration = 1000, Score = 1.959368\n",
      "51 best iteration = 753, Score = 0.471233\n",
      "52 best iteration = 1000, Score = 1.937669\n",
      "53 best iteration = 1000, Score = 1.956659\n",
      "54 best iteration = 1000, Score = 1.959367\n",
      "55 best iteration = 1000, Score = 0.792908\n",
      "56 best iteration = 1000, Score = 1.958034\n",
      "57 best iteration = 1000, Score = 1.939981\n",
      "58 best iteration = 1000, Score = 1.959366\n",
      "59 best iteration = 1000, Score = 1.825817\n",
      "60 best iteration = 1000, Score = 1.959366\n",
      "61 best iteration = 1000, Score = 0.512700\n",
      "62 best iteration = 1000, Score = 1.958686\n",
      "63 best iteration = 1000, Score = 0.777905\n",
      "64 best iteration = 1000, Score = 1.726285\n",
      "65 best iteration = 1000, Score = 1.959367\n",
      "66 best iteration = 1000, Score = 1.959368\n",
      "67 best iteration = 1000, Score = 1.728649\n",
      "68 best iteration = 1000, Score = 1.959219\n",
      "69 best iteration = 1000, Score = 1.959360\n",
      "70 best iteration = 1000, Score = 1.957993\n",
      "71 best iteration = 1000, Score = 1.957802\n",
      "72 best iteration = 1000, Score = 1.958501\n",
      "73 best iteration = 1000, Score = 1.178377\n",
      "74 best iteration = 1000, Score = 1.959272\n",
      "75 best iteration = 1000, Score = 1.404954\n",
      "76 best iteration = 1000, Score = 1.959368\n",
      "77 best iteration = 1000, Score = 1.959351\n",
      "78 best iteration = 1000, Score = 1.959343\n",
      "79 best iteration = 1000, Score = 1.741579\n",
      "80 best iteration = 1000, Score = 1.577893\n",
      "81 best iteration = 1000, Score = 1.959367\n",
      "82 best iteration = 1000, Score = 1.959029\n",
      "83 best iteration = 1000, Score = 1.837028\n",
      "84 best iteration = 1000, Score = 1.959355\n",
      "85 best iteration = 1000, Score = 1.958574\n",
      "86 best iteration = 1000, Score = 1.959368\n",
      "87 best iteration = 1000, Score = 1.959359\n",
      "88 best iteration = 1000, Score = 1.467301\n",
      "89 best iteration = 1000, Score = 1.959364\n",
      "90 best iteration = 1000, Score = 1.705582\n",
      "91 best iteration = 1000, Score = 0.467917\n",
      "92 best iteration = 1000, Score = 1.959176\n",
      "93 best iteration = 686, Score = 0.464596\n",
      "94 best iteration = 1000, Score = 1.959318\n",
      "95 best iteration = 1000, Score = 1.958245\n",
      "96 best iteration = 331, Score = 0.467238\n",
      "97 best iteration = 471, Score = 0.464225\n",
      "98 best iteration = 1000, Score = 1.955426\n",
      "99 best iteration = 1000, Score = 1.814725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loop</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>random_state</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>score</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.839381</td>\n",
       "      <td>0.035627</td>\n",
       "      <td>97</td>\n",
       "      <td>155</td>\n",
       "      <td>471</td>\n",
       "      <td>115</td>\n",
       "      <td>42</td>\n",
       "      <td>9.167532e-05</td>\n",
       "      <td>8.905643e-02</td>\n",
       "      <td>0.464225</td>\n",
       "      <td>0.751067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.685732</td>\n",
       "      <td>0.029846</td>\n",
       "      <td>93</td>\n",
       "      <td>105</td>\n",
       "      <td>686</td>\n",
       "      <td>77</td>\n",
       "      <td>42</td>\n",
       "      <td>1.064016e-09</td>\n",
       "      <td>5.580390e-03</td>\n",
       "      <td>0.464596</td>\n",
       "      <td>0.875661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.323569</td>\n",
       "      <td>0.022379</td>\n",
       "      <td>20</td>\n",
       "      <td>198</td>\n",
       "      <td>999</td>\n",
       "      <td>133</td>\n",
       "      <td>42</td>\n",
       "      <td>2.022127e-06</td>\n",
       "      <td>5.762190e-06</td>\n",
       "      <td>0.466578</td>\n",
       "      <td>0.759019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.945986</td>\n",
       "      <td>0.042999</td>\n",
       "      <td>96</td>\n",
       "      <td>140</td>\n",
       "      <td>331</td>\n",
       "      <td>167</td>\n",
       "      <td>42</td>\n",
       "      <td>7.695343e-02</td>\n",
       "      <td>7.120265e-13</td>\n",
       "      <td>0.467238</td>\n",
       "      <td>0.369918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.481572</td>\n",
       "      <td>0.010885</td>\n",
       "      <td>91</td>\n",
       "      <td>36</td>\n",
       "      <td>1000</td>\n",
       "      <td>154</td>\n",
       "      <td>42</td>\n",
       "      <td>2.530934e-05</td>\n",
       "      <td>1.836402e-12</td>\n",
       "      <td>0.467917</td>\n",
       "      <td>0.995576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.766205</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>753</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>1.603530e-03</td>\n",
       "      <td>3.822898e-07</td>\n",
       "      <td>0.471233</td>\n",
       "      <td>0.701068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.976127</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1000</td>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>8.323264e-10</td>\n",
       "      <td>2.418164e-15</td>\n",
       "      <td>0.476520</td>\n",
       "      <td>0.102678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.204935</td>\n",
       "      <td>0.083572</td>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "      <td>290</td>\n",
       "      <td>150</td>\n",
       "      <td>42</td>\n",
       "      <td>1.202683e-06</td>\n",
       "      <td>5.551291e-08</td>\n",
       "      <td>0.477120</td>\n",
       "      <td>0.633842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.896863</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1000</td>\n",
       "      <td>77</td>\n",
       "      <td>42</td>\n",
       "      <td>1.016945e-07</td>\n",
       "      <td>4.000593e-03</td>\n",
       "      <td>0.477120</td>\n",
       "      <td>0.704410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.791783</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>53</td>\n",
       "      <td>42</td>\n",
       "      <td>7.246879e-09</td>\n",
       "      <td>8.115956e-10</td>\n",
       "      <td>0.482146</td>\n",
       "      <td>0.382464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bytree  learning_rate  loop  min_child_samples  n_estimators  \\\n",
       "97          0.839381       0.035627    97                155           471   \n",
       "93          0.685732       0.029846    93                105           686   \n",
       "20          0.323569       0.022379    20                198           999   \n",
       "96          0.945986       0.042999    96                140           331   \n",
       "91          0.481572       0.010885    91                 36          1000   \n",
       "51          0.766205       0.025733    51                 11           753   \n",
       "4           0.976127       0.013967     4                 28          1000   \n",
       "26          0.204935       0.083572    26                 61           290   \n",
       "1           0.896863       0.012610     1                 48          1000   \n",
       "23          0.791783       0.014387    23                 30          1000   \n",
       "\n",
       "    num_leaves  random_state     reg_alpha    reg_lambda     score  subsample  \n",
       "97         115            42  9.167532e-05  8.905643e-02  0.464225   0.751067  \n",
       "93          77            42  1.064016e-09  5.580390e-03  0.464596   0.875661  \n",
       "20         133            42  2.022127e-06  5.762190e-06  0.466578   0.759019  \n",
       "96         167            42  7.695343e-02  7.120265e-13  0.467238   0.369918  \n",
       "91         154            42  2.530934e-05  1.836402e-12  0.467917   0.995576  \n",
       "51          72            42  1.603530e-03  3.822898e-07  0.471233   0.701068  \n",
       "4           90            42  8.323264e-10  2.418164e-15  0.476520   0.102678  \n",
       "26         150            42  1.202683e-06  5.551291e-08  0.477120   0.633842  \n",
       "1           77            42  1.016945e-07  4.000593e-03  0.477120   0.704410  \n",
       "23          53            42  7.246879e-09  8.115956e-10  0.482146   0.382464  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "random_state = 42\n",
    "\n",
    "today = str(datetime.now())\n",
    "filename = f'coarse-search {today}.csv'\n",
    "\n",
    "num_loop = 100\n",
    "n_estimators = 1000\n",
    "\n",
    "early_stopping_rounds = 20\n",
    "coarse_hyperparameters_list = []\n",
    "\n",
    "for loop in range(num_loop):\n",
    "    num_leaves = np.random.randint(10, 200)\n",
    "    min_child_samples = np.random.randint(2, 200)\n",
    "    subsample = np.random.uniform(0.1, 1.0)\n",
    "    colsample_bytree = np.random.uniform(0.1, 1.0)\n",
    "    learning_rate = 10 ** -np.random.uniform(low = 1, high = 10)\n",
    "    reg_alpha = 10 ** -np.random.uniform(low = 1, high = 10)\n",
    "    reg_lambda = 10 **  -np.random.uniform(low = 1, high = 15)\n",
    "    \n",
    "    parameters = {'loop': loop,\n",
    "                 'num_leaves': num_leaves,\n",
    "                 'min_child_samples': min_child_samples,\n",
    "                 'subsample': subsample,\n",
    "                 'colsample_bytree': colsample_bytree,\n",
    "                 'reg_alpha' : reg_alpha,\n",
    "                 'reg_lambda': reg_lambda,\n",
    "                 'n_estimators': n_estimators,\n",
    "                 'learning_rate': learning_rate,\n",
    "                 'random_state': random_state}\n",
    "    model = LGBMClassifier(**parameters)\n",
    "    \n",
    "    model.fit(X_train, y_train, \n",
    "             eval_set = [(X_val, y_val)],\n",
    "             verbose = 0,\n",
    "             early_stopping_rounds = early_stopping_rounds)\n",
    "    parameters['n_estimators'] = model.best_iteration_\n",
    "    parameters['score'] = model.best_score_['valid_0']['multi_logloss']\n",
    "    \n",
    "    print(f\"{loop:2} best iteration = {parameters['n_estimators']}, Score = {parameters['score']:.6f}\")\n",
    "    coarse_hyperparameters_list.append(parameters)\n",
    "    coarse_data = pd.DataFrame(coarse_hyperparameters_list).sort_values(by = 'score')\n",
    "    coarse_data.to_csv(filename)\n",
    "coarse_data.head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finer Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jongwoopark/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 best iteration = 1000, Score = 0.484933\n",
      " 1 best iteration = 1000, Score = 0.750323\n",
      " 2 best iteration = 1000, Score = 0.476805\n",
      " 3 best iteration = 1000, Score = 0.604865\n",
      " 4 best iteration = 1000, Score = 0.529964\n",
      " 5 best iteration = 1000, Score = 0.451976\n",
      " 6 best iteration = 1000, Score = 0.503133\n",
      " 7 best iteration = 1000, Score = 0.465870\n",
      " 8 best iteration = 1000, Score = 0.486997\n",
      " 9 best iteration = 1000, Score = 0.515116\n",
      "10 best iteration = 1000, Score = 0.490864\n",
      "11 best iteration = 1000, Score = 0.452408\n",
      "12 best iteration = 1000, Score = 0.662607\n",
      "13 best iteration = 1000, Score = 0.562853\n",
      "14 best iteration = 1000, Score = 0.730427\n",
      "15 best iteration = 1000, Score = 0.475624\n",
      "16 best iteration = 1000, Score = 0.517233\n",
      "17 best iteration = 1000, Score = 0.479102\n",
      "18 best iteration = 1000, Score = 0.505607\n",
      "19 best iteration = 1000, Score = 0.510558\n",
      "20 best iteration = 1000, Score = 0.813798\n",
      "21 best iteration = 1000, Score = 0.459713\n",
      "22 best iteration = 1000, Score = 0.499300\n",
      "23 best iteration = 1000, Score = 0.772833\n",
      "24 best iteration = 1000, Score = 0.726602\n",
      "25 best iteration = 1000, Score = 0.728584\n",
      "26 best iteration = 1000, Score = 0.509691\n",
      "27 best iteration = 1000, Score = 0.633629\n",
      "28 best iteration = 1000, Score = 0.821139\n",
      "29 best iteration = 1000, Score = 0.468243\n",
      "30 best iteration = 1000, Score = 0.467788\n",
      "31 best iteration = 1000, Score = 0.485942\n",
      "32 best iteration = 1000, Score = 0.880573\n",
      "33 best iteration = 1000, Score = 0.844427\n",
      "34 best iteration = 1000, Score = 0.462796\n",
      "35 best iteration = 1000, Score = 0.469398\n",
      "36 best iteration = 1000, Score = 1.019928\n",
      "37 best iteration = 1000, Score = 0.491946\n",
      "38 best iteration = 1000, Score = 0.546560\n",
      "39 best iteration = 1000, Score = 0.482593\n",
      "40 best iteration = 1000, Score = 0.708534\n",
      "41 best iteration = 1000, Score = 0.880835\n",
      "42 best iteration = 1000, Score = 0.832268\n",
      "43 best iteration = 1000, Score = 0.835876\n",
      "44 best iteration = 1000, Score = 0.478904\n",
      "45 best iteration = 1000, Score = 0.629517\n",
      "46 best iteration = 1000, Score = 0.458568\n",
      "47 best iteration = 1000, Score = 0.674837\n",
      "48 best iteration = 1000, Score = 0.617950\n",
      "49 best iteration = 1000, Score = 0.799805\n",
      "50 best iteration = 1000, Score = 0.575394\n",
      "51 best iteration = 1000, Score = 0.879378\n",
      "52 best iteration = 1000, Score = 0.499257\n",
      "53 best iteration = 1000, Score = 0.461940\n",
      "54 best iteration = 1000, Score = 0.483241\n",
      "55 best iteration = 1000, Score = 0.503277\n",
      "56 best iteration = 1000, Score = 0.739463\n",
      "57 best iteration = 1000, Score = 0.812621\n",
      "58 best iteration = 1000, Score = 0.564229\n",
      "59 best iteration = 1000, Score = 0.958381\n",
      "60 best iteration = 1000, Score = 0.452452\n",
      "61 best iteration = 1000, Score = 0.558710\n",
      "62 best iteration = 1000, Score = 0.751167\n",
      "63 best iteration = 1000, Score = 0.728182\n",
      "64 best iteration = 1000, Score = 0.500231\n",
      "65 best iteration = 1000, Score = 0.929139\n",
      "66 best iteration = 1000, Score = 1.001886\n",
      "67 best iteration = 1000, Score = 0.707549\n",
      "68 best iteration = 1000, Score = 0.455387\n",
      "69 best iteration = 1000, Score = 0.514793\n",
      "70 best iteration = 1000, Score = 0.578915\n",
      "71 best iteration = 1000, Score = 0.453180\n",
      "72 best iteration = 1000, Score = 0.463891\n",
      "73 best iteration = 1000, Score = 0.456370\n",
      "74 best iteration = 1000, Score = 0.762245\n",
      "75 best iteration = 1000, Score = 0.844984\n",
      "76 best iteration = 1000, Score = 0.537256\n",
      "77 best iteration = 1000, Score = 0.788798\n",
      "78 best iteration = 1000, Score = 0.802052\n",
      "79 best iteration = 1000, Score = 0.620063\n",
      "80 best iteration = 1000, Score = 0.505983\n",
      "81 best iteration = 1000, Score = 0.468456\n",
      "82 best iteration = 1000, Score = 0.662241\n",
      "83 best iteration = 1000, Score = 0.607151\n",
      "84 best iteration = 1000, Score = 0.501628\n",
      "85 best iteration = 1000, Score = 0.633203\n",
      "86 best iteration = 1000, Score = 0.453783\n",
      "87 best iteration = 1000, Score = 0.493028\n",
      "88 best iteration = 1000, Score = 0.462543\n",
      "89 best iteration = 1000, Score = 0.924000\n",
      "90 best iteration = 1000, Score = 0.517434\n",
      "91 best iteration = 1000, Score = 0.453834\n",
      "92 best iteration = 1000, Score = 0.558851\n",
      "93 best iteration = 1000, Score = 0.713435\n",
      "94 best iteration = 1000, Score = 0.838205\n",
      "95 best iteration = 1000, Score = 0.941838\n",
      "96 best iteration = 1000, Score = 0.642984\n",
      "97 best iteration = 1000, Score = 0.451595\n",
      "98 best iteration = 1000, Score = 0.684301\n",
      "99 best iteration = 1000, Score = 1.086490\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loop</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>random_state</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>score</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.666874</td>\n",
       "      <td>0.012523</td>\n",
       "      <td>97</td>\n",
       "      <td>70</td>\n",
       "      <td>1000</td>\n",
       "      <td>177</td>\n",
       "      <td>42</td>\n",
       "      <td>3.231114e-05</td>\n",
       "      <td>9.792592e-11</td>\n",
       "      <td>0.451595</td>\n",
       "      <td>0.662702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.532131</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>1000</td>\n",
       "      <td>163</td>\n",
       "      <td>42</td>\n",
       "      <td>4.062783e-04</td>\n",
       "      <td>2.142414e-14</td>\n",
       "      <td>0.451976</td>\n",
       "      <td>0.492984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.643945</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>1000</td>\n",
       "      <td>168</td>\n",
       "      <td>42</td>\n",
       "      <td>6.314948e-07</td>\n",
       "      <td>1.413943e-07</td>\n",
       "      <td>0.452408</td>\n",
       "      <td>0.423878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.472478</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>1000</td>\n",
       "      <td>106</td>\n",
       "      <td>42</td>\n",
       "      <td>4.273285e-04</td>\n",
       "      <td>1.771863e-12</td>\n",
       "      <td>0.452452</td>\n",
       "      <td>0.734406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.016636</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>1000</td>\n",
       "      <td>155</td>\n",
       "      <td>42</td>\n",
       "      <td>6.960306e-08</td>\n",
       "      <td>1.688497e-13</td>\n",
       "      <td>0.453180</td>\n",
       "      <td>0.778168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.705918</td>\n",
       "      <td>0.014331</td>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>1000</td>\n",
       "      <td>122</td>\n",
       "      <td>42</td>\n",
       "      <td>2.053456e-07</td>\n",
       "      <td>3.094597e-07</td>\n",
       "      <td>0.453783</td>\n",
       "      <td>0.740094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.496324</td>\n",
       "      <td>0.014816</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>1000</td>\n",
       "      <td>102</td>\n",
       "      <td>42</td>\n",
       "      <td>9.686146e-07</td>\n",
       "      <td>1.956898e-14</td>\n",
       "      <td>0.453834</td>\n",
       "      <td>0.607934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.733351</td>\n",
       "      <td>0.011267</td>\n",
       "      <td>68</td>\n",
       "      <td>91</td>\n",
       "      <td>1000</td>\n",
       "      <td>142</td>\n",
       "      <td>42</td>\n",
       "      <td>2.311402e-05</td>\n",
       "      <td>1.606608e-06</td>\n",
       "      <td>0.455387</td>\n",
       "      <td>0.668473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.849570</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>73</td>\n",
       "      <td>87</td>\n",
       "      <td>1000</td>\n",
       "      <td>192</td>\n",
       "      <td>42</td>\n",
       "      <td>3.531752e-04</td>\n",
       "      <td>1.615061e-15</td>\n",
       "      <td>0.456370</td>\n",
       "      <td>0.869767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.804699</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>46</td>\n",
       "      <td>62</td>\n",
       "      <td>1000</td>\n",
       "      <td>101</td>\n",
       "      <td>42</td>\n",
       "      <td>2.353404e-08</td>\n",
       "      <td>2.943259e-08</td>\n",
       "      <td>0.458568</td>\n",
       "      <td>0.488461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bytree  learning_rate  loop  min_child_samples  n_estimators  \\\n",
       "97          0.666874       0.012523    97                 70          1000   \n",
       "5           0.532131       0.011932     5                 51          1000   \n",
       "11          0.643945       0.011835    11                 54          1000   \n",
       "60          0.472478       0.020700    60                 54          1000   \n",
       "71          0.597342       0.016636    71                 71          1000   \n",
       "86          0.705918       0.014331    86                 66          1000   \n",
       "91          0.496324       0.014816    91                 89          1000   \n",
       "68          0.733351       0.011267    68                 91          1000   \n",
       "73          0.849570       0.010322    73                 87          1000   \n",
       "46          0.804699       0.018601    46                 62          1000   \n",
       "\n",
       "    num_leaves  random_state     reg_alpha    reg_lambda     score  subsample  \n",
       "97         177            42  3.231114e-05  9.792592e-11  0.451595   0.662702  \n",
       "5          163            42  4.062783e-04  2.142414e-14  0.451976   0.492984  \n",
       "11         168            42  6.314948e-07  1.413943e-07  0.452408   0.423878  \n",
       "60         106            42  4.273285e-04  1.771863e-12  0.452452   0.734406  \n",
       "71         155            42  6.960306e-08  1.688497e-13  0.453180   0.778168  \n",
       "86         122            42  2.053456e-07  3.094597e-07  0.453783   0.740094  \n",
       "91         102            42  9.686146e-07  1.956898e-14  0.453834   0.607934  \n",
       "68         142            42  2.311402e-05  1.606608e-06  0.455387   0.668473  \n",
       "73         192            42  3.531752e-04  1.615061e-15  0.456370   0.869767  \n",
       "46         101            42  2.353404e-08  2.943259e-08  0.458568   0.488461  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "today = str(datetime.now())\n",
    "filename = f'finer-search {today}.csv'\n",
    "num_loop = 100\n",
    "n_estimators = 1000\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state = random_state, shuffle=False)\n",
    "finer_hyperparameters_list = []\n",
    "\n",
    "for loop in range(num_loop):\n",
    "    num_leaves = np.random.randint(100, 200) # 10 -> 100\n",
    "    min_child_samples = np.random.randint(50, 100) # 2 -> 50\n",
    "    subsample = np.random.uniform(0.4, 0.9) # (0.1, 1.0) -> (0.4, 0.9)\n",
    "    colsample_bytree = np.random.uniform(0.4, 0.9) # (0.1, 1.0) -> (0.4, 0.9)\n",
    "    learning_rate = 10 ** -np.random.uniform(low = 0.9, high = 3) # (1, 10) -> (0.9, 3)\n",
    "    reg_alpha = 10 ** -np.random.uniform(low = 3, high = 8) # (1, 10) -> (3, 8)\n",
    "    reg_lambda = 10 **  -np.random.uniform(low = 5, high = 15) # (1, 15) -> (5, 15)\n",
    "    \n",
    "    parameters = {'loop': loop,\n",
    "                 'num_leaves': num_leaves,\n",
    "                 'min_child_samples': min_child_samples,\n",
    "                 'subsample': subsample,\n",
    "                 'colsample_bytree': colsample_bytree,\n",
    "                 'reg_alpha' : reg_alpha,\n",
    "                 'reg_lambda': reg_lambda,\n",
    "                 'n_estimators': n_estimators,\n",
    "                 'learning_rate': learning_rate,\n",
    "                 'random_state': random_state}\n",
    "    \n",
    "    fit_params = {'verbose': 0}\n",
    "    model = LGBMClassifier(**parameters)\n",
    "    \n",
    "    score = cross_val_score(model, X, y, cv = kf, fit_params = fit_params, scoring = 'neg_log_loss').mean()\n",
    "    score = -1.0 * score\n",
    "    parameters['score'] = score\n",
    "    \n",
    "    \n",
    "    print(f\"{loop:2} best iteration = {parameters['n_estimators']}, Score = {parameters['score']:.6f}\")\n",
    "    finer_hyperparameters_list.append(parameters)\n",
    "    finer_data = pd.DataFrame(finer_hyperparameters_list).sort_values(by = 'score')\n",
    "    finer_data.to_csv(filename)\n",
    "finer_data.head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colsample_bytree     5.321307e-01\n",
       "learning_rate        1.193170e-02\n",
       "loop                 5.000000e+00\n",
       "min_child_samples    5.100000e+01\n",
       "n_estimators         1.000000e+03\n",
       "num_leaves           1.630000e+02\n",
       "random_state         4.200000e+01\n",
       "reg_alpha            4.062783e-04\n",
       "reg_lambda           2.142414e-14\n",
       "score                4.519759e-01\n",
       "subsample            4.929844e-01\n",
       "Name: 5, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finer_data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.5321307, learning_rate=0.0119317, loop=5,\n",
       "               min_child_samples=51, n_estimators=1000, num_leaves=163,\n",
       "               random_state=42, reg_alpha=0.0004062783, reg_lambda=2.142414e-14,\n",
       "               subsample=0.4929844)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier(colsample_bytree=     5.321307e-01,\n",
    "                        learning_rate=        1.193170e-02,\n",
    "                        loop=                 5,\n",
    "                        min_child_samples=    51,\n",
    "                        n_estimators=         1000,\n",
    "                        num_leaves=           163,\n",
    "                        reg_alpha=            4.062783e-04,\n",
    "                        reg_lambda=           2.142414e-14,\n",
    "                        subsample=            4.929844e-01,\n",
    "                       random_state = random_state)\n",
    "\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.46208\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits = 5,\n",
    "                        random_state = random_state,\n",
    "                        shuffle = False)\n",
    "\n",
    "fit_params = {'verbose' : 0}\n",
    "score = cross_val_score(model, X_train, y_train, cv = kf, \n",
    "                       fit_params = fit_params, scoring = 'neg_log_loss').mean()\n",
    "\n",
    "score = -1.0 * score\n",
    "print(f\"Score = {score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.5321307, learning_rate=0.0119317, loop=5,\n",
       "               min_child_samples=51, n_estimators=1000, num_leaves=163,\n",
       "               random_state=42, reg_alpha=0.0004062783, reg_lambda=2.142414e-14,\n",
       "               subsample=0.4929844)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144368, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "      <th>Class_4</th>\n",
       "      <th>Class_5</th>\n",
       "      <th>Class_6</th>\n",
       "      <th>Class_7</th>\n",
       "      <th>Class_8</th>\n",
       "      <th>Class_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.133320</td>\n",
       "      <td>0.130002</td>\n",
       "      <td>0.730854</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.016353</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.354740</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.620089</td>\n",
       "      <td>0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.998990</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.625624</td>\n",
       "      <td>0.366435</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.001822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135010</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.062923</td>\n",
       "      <td>0.787123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class_1   Class_2   Class_3   Class_4   Class_5   Class_6   Class_7  \\\n",
       "id                                                                         \n",
       "1   0.000214  0.133320  0.130002  0.730854  0.000065  0.000905  0.003594   \n",
       "2   0.001494  0.016353  0.003402  0.000892  0.000349  0.354740  0.001150   \n",
       "3   0.000015  0.000092  0.000078  0.000032  0.000005  0.998990  0.000024   \n",
       "4   0.000272  0.625624  0.366435  0.003672  0.000098  0.000944  0.000402   \n",
       "5   0.135010  0.001768  0.002398  0.000611  0.000273  0.006154  0.003740   \n",
       "\n",
       "     Class_8   Class_9  \n",
       "id                      \n",
       "1   0.000775  0.000271  \n",
       "2   0.620089  0.001531  \n",
       "3   0.000739  0.000027  \n",
       "4   0.000732  0.001822  \n",
       "5   0.062923  0.787123  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('data/sampleSubmission.csv', index_col = 'id')\n",
    "submit = pd.DataFrame(prediction, index = submit.index, columns = model.classes_)\n",
    "print(submit.shape)\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('otto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
